---
title: "Problem set 1"
author: "Jason Parker"
student: "Firas Obeid"
date: "Due Sept 17th"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/Firo Obeid/Desktop/Financial Engineering/FALL 2019/Advanced Financial Analytics/R_Files")

rm(list=ls())
library(data.table)
library(ggplot2)
library(dbConnect)
library(RSQLite)
library(DBI)
library(rlang)
library(broom)
wpull <- function(tablename){
  con <- DBI::dbConnect(RSQLite::SQLite(),'wooldridge2.db')
  dt <- DBI::dbReadTable(con,tablename)
  dt <- data.table(dt)
  print(DBI::dbReadTable(con,paste(tablename,'labels',sep='_')))
  DBI::dbDisconnect(con)
  rm(con)
  return(dt)
}
```
# Brooks Questions:

Use R for the Chris Brooks problems. You can find any of the data sets on the book [website](https://www.cambridge.org/us/academic/subjects/economics/finance/introductory-econometrics-finance-4th-edition).

##Questions 3.5-3.9.

#Question 3.5:
$$Yt= ?? + ??xt + ut$$
Since alfa and beta are linear, OLS can be used

1.$ Y_t= e^??Xt^??x^{u_t}$$
Can be estimated using OLS. Just transform the model by appling logs both sides.

$$Yt= ?? + ????X_t+ u_t$$
Yes we can use OLS. The result will be the two coefs multiplies by eachother.

$$. ln(Y_t) = ?? + ??ln(x_t) + u_t$$
Can be estimated using OLS!

$$. Y_t= ?? + ??x_tz_t+ u_t$$
Can be estimated using OLS, params are linear yet variables are not!

##Question 3.6:
$$H_0 : beta = 1  ; H_A: beta >1$$
```{r}
n = 60
df = 2 
t_stats = (1.147-1) / 0.0548
t_cv = qt(1-0.05,n-df) #one-sided
paste("Since", t_stats, ">", t_cv,", we reject the null hypo. at 5% significance and conclude that the security is more risky then the market since BETA > 1.")

```
##Question 3.7:
Since there is no systematic risk then beta = 0!
$$H_0 : beta = 1  ; H_A: beta ??? 0 $$

```{r}
n = 38
df = 2
t_stats = (0.214-0) / 0.186
t_cv = qt(1-(0.05/2),n-df) #Two-sided
t_cv
paste("Since ", t_stats, "<", t_cv,", we fail to reject the null hypo. and conclude that the beta is statistically significant not different from zero or that the security at 5% sig. level ")
```
##Question 3.8:
95% Confidence Interval:
```{r}
c(0.214-t_cv*0.186,0.214+t_cv*0.186)
```
99% Confidence Interval:
```{r}
t_cv_1 = qt(1-(0.01/2),n-df)
c(0.214-t_cv_1*0.186,0.214+t_cv_1*0.186)
```
##Question 3.9:
We use the values of the estimated coefs in the hypothesis testing to make an inference about the actual coefs values!

##Questions 4.1-4.6.
```{R}
paste("Question 4.1")

n <- 100
alpha <- 0.05
t <- qt((1 - alpha/2), n-1)
onetail_t<- t** 2
onetail_t
f_test <- qf(1- alpha, 1 , n-1) 
f_test
paste("t_test = ftest meaning upper tail or absolute t-distribution follows F-distribution at alfa!")

paste("Question 4.2")
paste("Usuay: t-test is for individual coef's and ftest for joint hypothesis")
paste("a)B3 = 2: (Number of restrictions = 1)  Use either f-test or t-test ")

paste("b) B3 + B4 = 1: (Number of restriction = 1), Use f-test for joint coefs hypo testing! ")

paste("c) B3 + B4 = 1 & B5=1: (Number of restrictions = 2) use f-test only")

paste("d) B2=B3=B4=B5=0: (Number of restrictions = 4) Only F-test")

paste("e) B2*B3=1: Since, the model is non-linear we can not use f-test neither t-test")

paste("Question 4.3")
paste("Part d) B2=B3=B4=B5=0 is the the hypothesis for our regression equation. The alternative hypo. is the at least one of the beta is different from zero!")

paste("Question 4.4")
paste("The restricted residual sum of squares >= unrestricted residual sum of square.The residual sum of squares is minimized with respect to the model's parameters.Meaning all the parameters should be included.  Whereas in the restricted regression the coefficients are restricted which means the restrictions are imposed on beta's so that the original data is transformed, making the residual sum of sqaures greater than or equal to the unrestricted Restriction is done to check if the restriction is significantly by assigning a zero coeficient on restricted variables !")
paste("Question 4.5")
f_stat= ((102.87 - 91.41) / 91.41) * ((96 - 5) / 2)
#df1=m=number of restrictions
#df2 = n = sample size
#k = number of coefs- 1(if their is an intercept)
f_5 = qf(1-0.05, 2, 91)#upper tail
f_1 <- qf(1-0.01, 2, 91)
cat("H0: ??3 + ??4 = 1 and ??5 = 1",
"y = ??1 + ??2x2 + ??3x3 + ??4x4 + ??5x5 + u",
"If ??4 = 1 - ??3 and ??5 = 1",
"y = ??1 + ??2x2 + ??3x3 + (1 - ??3)x3 + x5 + u",
"y = ??1 + ??2x2 + ??3x3 + x4 - ??3x4 + x5 + u",
"y - x4 - x5 = ??1 + ??2x2 + ??3(x3 - x4) + u",
"Let P = y - x4 - x5 and Q = x3 - x4",
"Then P = ??1 + ??2x2 + ??3Q + u",
"n = 96, RRSS = 102.87, URSS = 91.41, m=5-3",
"f_stat = [(RRSS - URSS) / URSS] * [(n - k) / m]",  
f_stat,
"F at 5% level of significance =",
f_5,
"F at 1% level of significance =",
f_1,
"Since the calculated F is greater than the F at 5% and 1%,we reject the null hypothesis at 5% and 1% level of significance concluding that either restrictions are not supported or significant by the given data", sep = "\n")
cat("Question 4.6",
"ri = ??0 + ??1Si + ??2MBi + ??3PEi + ??4BETAi + ui",
"B0 = 0.080, SE(B0) = 0.064",
"B1 = 0.801, SE(B1) = 0.147", 
"B2 = 0.321, SE(B2) = 0.136", 
"B3 = 0.164, SE(B3) = 0.420", 
"B4 = -0.084, SE(B4) = 0.120",
"n = 200, k = 2",
"FIRM SIZE: H0: B1 = 0 H1: B1 ??? 0",
"The t ratios to test is t = (??1 - B1) / SE(??1)",
t = (0.801 - 0) / 0.147,
"t statistic at 5% and 1% level of significance",
t_5 <- qt((1-0.05/2), 198),
t_1 <- qt((1-0.01/2), 198),
"Since t-stat > t_5% and t_1% we reject the null hypo. and conclude firm size has effect on explaining return",
"M/B Ratio: H0: B2 = 0 H1: B2 ??? 0",
"The t ratios to test is t = (??2 - B2) / SE(??2)",
t = (0.321 - 0) / 0.136,
"Since  t_5% < t-stat < t_1% we reject the null at 5% significance but fail to reject the null at 1% significance level! M/B ratio has no significant effect on returns at 1% sig. level!",
"P/E Ratio: H0: B3 = 0 H1: B3 ??? 0",
"The test statistic is: t = (??3 - ??3) / SE(??3)",
t = ((0.164 - 0) / 0.420),
"Since t-stat< t_5% & t_1% we fail to reject the null and conclude that P/E ratio has no effect on returns!",
"BETA(Sensitivity to market returns): H0: B4 = 1 H1: B4 ??? 1 1 not 0!",
"The test statistic is: t = (??3 - ??3) / SE(??3)",
t = -((-0.084 -1) / 0.120),
"Since t_stat >>  t_5% & t_1% thus the null is rejected and conclude that BETA has effect on returns and firm's BETA is sensitive to market returns(or Market Beta. The coef of this variable states that when stocks beta is 1, returns drop by -0.084 or -8.4%! This is not true, as when beta is 1 this should not effect returns! Imagine BETA to be 2, thus returns drop by -16.8% where in reality they should increase!!!)",
sep = '\n')
```

# Supplementary Questions:

In the supplementary questions, the data sets are available as tables in the ```wooldridge2.db``` file. 

## Question 1

An idempotent matrix $A$ is one where $AA=A$. In this question, use that $\hat\beta=(X'X)^{-1}X'y$ and $y=X\beta+e$. Define $P=X(X'X)^{-1}X'$ and $M=I_n-P_X$. Show the following:

i. $P$ is idempotent
$$P = X(X'X)^{-1}X'*X(X'X)^{-1}X'$$
$$=X(X'X)^{-1}X'=P$$

ii. $M$ is idempotent
$$(I_n-P_X)*I_n-P_X$$
$$I_nI_n -2I_nP_X + P_XP_X = I_n - 2P_X + P_X = I_n - P_X$$
iii. $\hat{y}=P y$
$$\hat{y}$$
$$= X(X'X)^{-1}X'* (X\beta+e)$$
$$\hat{y} = X\hat\beta + e;\hat\beta=(X'X)^{-1}X'y$$
$$= X (X'X)^{-1}X'y + e ; where P=X(X'X)^{-1}X'$$
$$Py + e ; e = 0---->M=Py$$
            
iv. $\hat{e}=M y$
$$\hat{e}=y???\hat{y}=My$$
$$M =  I - X(X'X)^{-1}X'$$
v. $y=P y+M y$
$$\hat{y} = X\hat\beta + e$$
$$= X(X'X)^{-1}X'y + e  = Py + My$$
vi. $\hat{y}\perp\hat{e}$
If dot product = 0 then they are orthogonal.
$$\hat{y} = Py --\hat{e'}= My  -->\hat{y'}My=(Py){'} (I - P)y = 0$$
$$y'P(I - P)y = 0$$
$$y'(P - PP)y = 0-->y'(P - P)y=0-->y'0y==0$$
$$y'*0*y = 0$$; They are orthogonal

## Question 2
The data in ```meap01``` table are for the state of Michigan in the year $2001$. Use these data to answer the following questions.

1. Find the largest and smallest values of math4. Does the range make sense? Explain.
```{R, eval = TRUE}
meap01 <- wpull('meap01')
summary(meap01$math4)
paste("The range do make sense since math scores should range between 0-100")
```
2. How many schools have a perfect pass rate on the math test? What percentage is this of the total sample?
```{R}
x = sum(meap01$math4 > 99)
y = (sum(meap01$math4 > 99) / length(meap01$index)) * 100 
paste("Schools with perfect pass rate: ", x)
paste("% of total sample is: ", y,"%")
```
3. How many schools have math pass rates of exactly $50\%$?
```{R}
sum(meap01$math4 == 50)

```
4. Compare the average pass rates for the math and reading scores. Which test is harder to pass?
```{R}
math = mean(meap01$math4,trim = 0.5)
read = mean(meap01$read4,trim = 0.5)
paste(math, ">",read ,math > read, "Reading is harder then math")
```

5. Find the correlation between math4 and read4. What do you conclude?
```{R}
cor(meap01$math4, meap01$read4 )
paste("Strong linear relationship since a high pass rate on math corrs with high pass rate on reading.")
```
6. The variable exppp is expenditure per pupil. Find the average of exppp along with its standard deviation. Would you say there is wide variation in per pupil spending?
```{R}
u = mean(meap01$exppp)
std = sd(meap01$exppp) / mean(meap01$exppp)
mean(meap01$exppp) + sd(meap01$exppp) / mean(meap01$exppp)
c(u-2*std, u+2*std)
paste("Not much variation in per pupil spending!")
```
7. Suppose School A spends $\$6000$ per student and School B spends $\$5500$ per student. By what percentage does School A's spending exceed School B's? Compare this to $100*[\ln(6000) - \ln(5500)]$, which is the approximation percentage difference based on the difference in the natural logs.
```{R}
percent =((6000-5500)/5500)*100
log_diff = 100 * (log(6000/5500))
paste(percent, ">", log_diff, "Log difference is always more conservative than simple percentage difference.")
```
## Question 3
The data in ```401k``` are a subset of data analyzed by Papke ($1995$) to study the relationship between participation in a $401(k)$ pension plan and the generosity of the plan. The variable prate is the percentage of eligible workers with an active account; this is the variable we would like to explain. The measure of generosity is the plan match rate, mrate. This variable gives the average amount the firm contributes to each worker's plan for each $\$1$ contribution by the worker. For example, if $mrate=0.50$, then a $\$1$ contribution by the worker is matched by a $50?$ contribution by the firm. 

1. Find the average participation rate and the average match rate in the sample of plans.
```{R}
four01k = wpull('401k')
c("Avg participation rate","Avg match rate")
c(mean(four01k$prate),mean(four01k$mrate))
```
2. Now, estimate the simple regression equation: $$\hat{prate} = \hat{\beta}_0+\hat{\beta}_1 mrate,$$ and report the results along with the sample size and R-squared.
```{R}
model = lm(prate~mrate, data = four01k)
r_sq = summary(model)$r.square
c(model$coefficients, model$df.residual +2, r_sq*100)
```

3. Interpret the intercept in your equation. Interpret the coefficient on ```mrate```.
```{R}
coef(model)
paste("Even when the match rate is 0, the participation rate is 83.07%. A $1 increase mrate, will increase participation rate to 98%. The interpretation is misleading as participation cant go above 100%.")
```
4. Find the predicted ```prate``` when $mrate=3.5$. Is this a reasonable prediction? Explain what is happening here.
```{R}
as.numeric(model$coefficients[1] + 3.5 * model$coefficients[2])
paste("Impossible!Linear regression model is giving unreasonable outcome for the dependent variable that should be bounded between 0 and 100, given that the number of mrate >= 3.5 is", sum(four01k$mrate >= 3.5),"!")
```
5. How much of the variation in ```prate``` is explained by ```mrate```? 
```{R}
paste("Looking at the R square score of", round(r_sq*100,digits = 2),"%",", only 7.5% of prate is explained by mrate. Thus other independent variables are needed to explain prate!")
```

## Question 4
The data set in ```ceosal2``` contains information on chief executive officers for U.S. corporations. The variable salary is annual compensation, in thousands of dollars, and ceoten is prior number of years as company CEO.

1. Find the average salary and the average tenure in the sample.
```{R}
ceosal2 = wpull('ceosal2')
mean(ceosal2$salary)
mean(ceosal2$ceoten)
```
2. How many CEOs are in their first year as CEO (that is, $ceoten=0$)? What is the longest tenure as a CEO?
```{r}
paste("CEOs that are in their first year as CEO ares",sum(ceosal2$ceoten <1))
paste("Longest tenure is :", max(ceosal2$ceoten))
```
3. Estimate the simple regression model $$\ln[salary]=\beta_0+\beta_1 ceoten+u$$ and report your results in the usual form. What is the (approximate) predicted percentage increase in salary given one more year as a CEO?
```{R}
model1 = lm(log(salary)~ceoten, data = ceosal2)
tidy(summary(model1))
paste("A one year increase in tenure(ceoten variable) increases salary by", 100*0.0097,"%. Since salary was bounded by 0-1 as ln(salary in the model.")
```
## Question 5
Use the data in ```wage2``` to estimate a simple regression explaining monthly salary (```wage```) in terms of IQ score (```IQ```).
```{r}
wage2 = wpull("wage2")
```
1. Find the average salary and average IQ in the sample. What is the sample standard deviation of IQ? (IQ scores are standardized so that the average in the population is $100$ with a standard deviation equal to $15$.)
```{r}
paste("Wage mean",mean(wage2$wage, trim = 2),"IQ mean", mean(wage2$IQ, trim = 2), "Std of IQ is", round(sd(wage2$IQ),digits = 2))

```
2. Estimate a simple regression model where a one-point increase in IQ changes wage by a constant dollar amount. Use this model to find the predicted increase in wage for an increase in IQ of $15$ points. Does IQ explain most of the variation in wage?
```{r}
model3 = lm(wage~IQ, data=wage2)
model3$coefficients
glance(model3)
predict = as.numeric(15*model3$coefficients[2])
paste("Our prediction increase is", round(predict, digits = 2),". IQ barely  explains 9.5% of the variation in wage!")

```
3. Now, estimate a model where each one-point increase in IQ has the same percentage effect on wage. If IQ increases by $15$ points, what is the approximate percentage increase in predicted wage?
```{r}
ln_model3 = lm(log(wage)~IQ, data=wage2)
ln_model3$coefficients
glance(ln_model3)
predict1 = as.numeric(100*15*ln_model3$coefficients[2])
paste("Our prediction is", round(predict1, digits = 2),"%increase in wage.")
```
## Question 6
Using the ```meap93``` data, we want to explore the relationship between the math pass rate (```math10```) and spending per student (```expend```).
```{R}
meap93 = wpull('meap93')
```
1. Do you think each additional dollar spent has the same effect on the pass rate, or does a diminishing effect seem more appropriate? Explain.
```{r}
paste("Each dollar spent does not have the same effect. If a school used to already spend much, then pass rate wont get affected, whereas if the school starts spending like never before, than that will certainly have an effect!")
```
2. In the population model, $$math10 = \beta_0+\beta_1 \ln[expend] + u$$ argue that $\beta_1/10$ is the percentage point change in math10 given a $10\%$ increase in expend.
```{R}
print("Since the model is a linear-log model, a 1% change in expend  changes math10 by beta1/100 since expend is bound between 0-1. Thus 10% change in expend changes math10 by beta1/10(beta1*10/100.")
```
3. Estimate this model. Report the estimated equation in the usual way, including the sample size and R-squared.
```{r}
model4 = lm(math10~log(expend), data = meap93)
tidy(summary(model4))
glance(model4)
n = model4$df.residual+length(model4$coefficients)
paste("Sample Size is:",n)
```
4. How big is the estimated spending effect? Namely, if spending increases by $10\%$, what is the estimated percentage point increase in ```math10```?
```{R}
paste("Change in math10 due to a 10% change in estimated spending is", (model4$coefficients[2]*0.10),"%")
```
5. One might worry that regression analysis can produce fitted values for ```math10``` that are greater than $100$. Why is this not much of a worry in this data set?
```{r}
paste("Recall max math score in data is :", max(meap93$math10), "The largest fitted value using the model is: ", model4$coefficients[1]+100)
```

## Question 7
Use the data in ```hprice1``` to estimate the model $$price=\beta_0+\beta_1 sqrft+\beta_2 bdrms + u,$$ where price is the house price measured in thousands of dollars.
```{R}
hprice1 = wpull("hprice1")
```

1. Write out the results in equation form.
```{R}
model5 = lm(price~sqrft+bdrms, data=hprice1)
intercept = model5$coefficients[1]
B_1 = round(model5$coefficients[2],3)
B_2 = round(model5$coefficients[3],3)
r_sqrd = summary(model5)$r.square
(c(intercept,B_1,B_2, r_sqrd))
```
2. What is the estimated increase in price for a house with one more bedroom, holding square footage constant?
```{R}
paste("House price increases by", B_2," for one more bedroom holding sqrft constant.")
```
3. What is the estimated increase in price for a house with an additional bedroom that is $140$ square feet in size? Compare this to your answer from above.
```{R}
paste("House price increase will be $",140*B_1+B_2)
```
4. What percentage of the variation in price is explained by square footage and number of bedrooms?
```{R}
(r_sqrd)*100
```
5. The first house in the sample has $sqrft=2438$ and $bdrms=4$. Find the predicted selling price for this house from the OLS regression line.
```{R}
x = round(as.numeric(intercept +2438*B_1+4*B_2),3)
c((paste("In thousands")),x)
```
6. The actual selling price of the first house in the sample was \$300000 (so $price=300$). Find the residual for this house. Does it suggest that the buyer underpaid or overpaid for the house?
```{R}
paste("Since x*1000 > 300000", ",The residual is", (x *1000 - 300000), "and the buyer underpaid! Lucky for him! Yet other factors might not have been reflected or measured by the model (Omitted Variable bias)")
```

## Question 8
The file ```ceosal2``` contains data on $177$ chief executive officers and can be used to examine the effects of firm performance on CEO salary.
```{R}
ceosal2 = wpull("ceosal2")
```

1. Estimate a model relating annual salary to firm sales and market value. Make the model of the constant elasticity variety for both independent variables. Write the results out in equation form.
```{R}
paste("Constant Elasticity = Log-log model")
model6 = lm(log(salary)~log(sales) + log(mktval), data = ceosal2)
bet_0 = model6$coefficients[1]
bet_1 = model6$coefficients[2]
bet_2 = model6$coefficients[3]
r_2 = summary(model6)$r.square
obs = model6$df.residual+length(model6$coefficients)
(c(bet_0,bet_1,bet_2,r_2,obs))
```
2. Add profits to the model. Why can this variable not be included in logarithmic form? Would you say that these firm performance variables explain most of the variation in CEO salaries?
```{R}
model6_new = lm(log(salary)~log(sales) + log(mktval) + profits, data = ceosal2)
bet_0_1 = round(model6_new$coefficients[1], digits =2)
bet_1_1 = round(model6_new$coefficients[2], digits =2)
bet_2_1 = round(model6_new$coefficients[3], digits =2)
bet_3 = round(model6_new$coefficients[4], digits =2)
r_2_1 = round(summary(model6_new)$r.square, digit = 2)

(c(bet_0_1,bet_1_1,bet_2_1, bet_3, r_2_1))
paste("log of profits is not permissible since profits can be negative!")
paste("Since r_2 is 0.3, these two variables do not explain a considerable amount off variation in CEOs salaries! Even profits seems to not explain log(salary) since its beta~0.")
```
3. Now also add the variable ceoten to the model. What is the estimated percentage return for another year of CEO tenure, holding other factors fixed?
```{R}
model6_new = lm(log(salary)~log(sales) + log(mktval) + profits +ceoten, data = ceosal2)
bet_0_1 = round(model6_new$coefficients[1], digits =2)
bet_1_1 = round(model6_new$coefficients[2], digits =2)
bet_2_1 = round(model6_new$coefficients[3], digits =2)
bet_3 = round(model6_new$coefficients[4], digits =2)
bet_4 = round(model6_new$coefficients[5], digits =2)
r_2_1 = round(summary(model6_new)$r.square, digit = 2)

(c(bet_0_1,bet_1_1,bet_2_1, bet_3,bet_4, r_2_1))
paste("A one year increase in CEO tenure will increase salary by", bet_4*100,"%")
```
4. Find the sample correlation coefficient between the variables $log(mktval)$ and $profits$. Are these variables highly correlated? What does this say about the OLS estimators?
```{R}
cor(log(ceosal2$mktval), ceosal2$profits)
paste("The correlation between these two variabes is high! Multicolinearity exists in our model! This increases the variance and SE in the estimates and estimators will become sensitive to specification.")
```

## Question 9
Use the data in ```attend``` for this exercise. Create the variable ```atndrte``` which is $attend/32$ because there were $32$ classes.
```{R}
attend = wpull("attend")
atndre = attend/32
```
1. Obtain the minimum, maximum, and average values for the variables ```atndrte```, ```priGPA```, and ```ACT```.
```{r}
summary(attend$atndrte)
summary(attend$priGPA)
summary(attend$ACT)
```
2. Estimate the model $$atndrte=\beta_0+\beta_1 GPA + \beta_2 ACT + u$$ and write the results in equation form. Interpret the intercept. Does it have a useful meaning?
```{R}
model7 = lm(atndrte~priGPA+ACT, data=attend)
b_0 = round(model7$coefficients[1], digits =2)
b_1 = round(model7$coefficients[2], digits =2)
b_2 = round(model7$coefficients[3], digits =2)
r2 = round(summary(model6_new)$r.square, digit = 2)
nobs = model7$df.residual+length(model7$coefficients)
(c(b_0, b_1, b_2, r2))
paste("Our intercept is not usefull here as it does not tell us anything for no gpa or ACT.")
```
3. Discuss the estimated slope coefficients. Are there any surprises?
```{R}
paste("ACT slope coeff if off surprise as increase in 1 ACT decreaces attendance")
```
4. What is the predicted ```atndrte``` if $priGPA=3.65$ and $ACT=20$? What do you make of this result? Are there any students in the sample with these values of the explanatory variables?
```{R}
b_0 + b_1*3.65 + b_2*20
sum(attend$priGPA ==3.65 & attend$ACT ==20)
paste("Yes only one! This result is impossible! Attendance should be bounf bw 0-100")
```
5. If Student A has $priGPA=3.1$ and $ACT=21$ and Student B has $priGPA=2.1$ and $ACT=26$, what is the predicted difference in their attendance rates?
```{R}
b_0 + b_1*3.1 + b_2*21 -(b_0 + b_1*2.1 + b_2*26)

```

## Question 10
Use the data in ```htv``` to answer this question. The data set includes information on wages, education, parents' education, and several other variables for $1,230$ working men in $1991$.
```{R}
htv = wpull("htv")
```
1. What is the range of the educ variable in the sample? What percentage of men completed 12th grade but no higher grade? Do the men or their parents have, on average, higher levels of education?
```{R}
paste("The range of educ is: ", as.numeric(summary(htv$educ)[6] - summary(htv$educ)[1]))
paste("% of men who completed 12th grade:", round((sum(htv$educ == 12) / length(htv$educ)*100),digits = 3))
```
2. Estimate the regression model $$educ=\beta_0+\beta_1 motheduc+\beta_2 fatheduc+u$$ by OLS and report the results in the usual form. How much sample variation in educ is explained by parents' education? Interpret the coefficient on motheduc.
```{R}
lm = lm(educ~motheduc+fatheduc, data = htv)
bt_0 = round(lm$coefficients[1], digits =3)
bt_1 = round(lm$coefficients[2], digits =3)
bt_2 = round(lm$coefficients[3], digits =3)
rs2 = round(summary(lm)$r.square, digit = 2)
nobs = lm$df.residual+length(model7$coefficients)
(c(bt_0, bt_1, bt_2, rs2))
paste("Mothers education explains more the men's education level! For every  year increase in mothers education, the men's education will be 0.302/yrs higher!")
```
3. Add the variable abil (a measure of cognitive ability) to the regression above, and report the results in equation form. Does ```ability``` help to explain variations in education, even after controlling for parents' education? Explain.
```{R}
lm_new = lm(educ~motheduc+fatheduc+abil, data = htv)
(c(lm_new$coefficients, summary(lm_new)$r.square))
paste("The ability variable improves the explanation of the men's education as its statistically significant different from zero!")
```
4. Now estimate an equation where abil appears in quadratic form: $$educ=\beta_0+\beta_1 motheduc+\beta_2 fatheduc+\beta_3 abil+\beta_4{abil}^2+u.$$ With the estimated coefficients on ability, use calculus to find the value of abil where educ is minimized. (The other coefficients and values of parents' education variables have no effect; we are holding parents' education fixed.) Notice that abil is measured so that negative values are permissible. You might also verify that the second derivative is positive so that you do indeed have a minimum.
```{R}
lm_quad = lm(educ~motheduc+fatheduc+abil+ I(abil^2) , data = htv)
(c(lm_quad$coefficients, summary(lm_quad)$r.square))
summary(htv$abil)
```
$$educ=8.240+ 0.19 motheduc+0.108 fatheduc+0.401 abil+0.051{abil}^2+u$$
$$d(educ)/d(abil) = .401 + .10abil = 0$$
$$abil = -4.01$$
$${d}^2(educ)/{d}^2(abil) =.10 >0 |local minimum |$$




5. Argue that only a small fraction of men in the sample have ```ability``` less than the value calculated above. Why is this important?
```{R}
paste("Only ", sum(htv$abil < -4.01),"have cog. ability less then -4.01 which is about ~ ",round(100*sum(htv$abil < -4.01)/length(htv$abil), digits = 3),"%")
```
6. Use the estimates above to plot the relationship beween the predicted education and abil. Let ```motheduc``` and ```fatheduc``` have their average values in the sample, $12.18$ and $12.45$, respectively.
```{r}
motheduc <- as.numeric(mean(htv$motheduc))
fatheduc <- as.numeric(mean(htv$fatheduc))

modelb = lm(educ~abil+I(abil^2),data = htv)
summary(modelb)

ggplot(htv,aes(x=abil,y=educ)) + 
  geom_point() + 
  geom_line(aes(y=predict(modelb)),color='red') + 
  scale_x_continuous('Men education') +
  scale_y_continuous('Ability')
```
